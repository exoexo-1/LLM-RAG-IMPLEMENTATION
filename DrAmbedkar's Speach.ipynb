{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f744fdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Extras\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.llms import Ollama\n",
    "import requests\n",
    "import ollama\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacb7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "MODEL = \"Mistral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48fd086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling f5074b1221da: 100% ▕██████████████████▏ 4.4 GB                         \u001b[K\n",
      "pulling 43070e2d4e53: 100% ▕██████████████████▏  11 KB                         \u001b[K\n",
      "pulling 1ff5b64b61b9: 100% ▕██████████████████▏  799 B                         \u001b[K\n",
      "pulling ed11eda7790d: 100% ▕██████████████████▏   30 B                         \u001b[K\n",
      "pulling 1064e17101bd: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# checking if model is available locally\n",
    "!ollama pull Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3ba6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! I'm an AI model designed to assist with various tasks and provide information. How can I help you today? I don't have personal feelings or experiences, but I'm here to make your life easier. As for the model, I'm a text-based AI trained by Mistral AI.\n",
      "\n",
      "If you're looking for something specific or need help with a particular problem, feel free to ask! I'm here to help.\n"
     ]
    }
   ],
   "source": [
    "# testing ollama chat\n",
    "\n",
    "messages = {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},{\"role\": \"user\", \"content\": \"Hello, how are you and who are you? what kinda model are you\"}\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee92cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant that provides answer to the question about Dr. B.R. Ambedkar's speeches. And you'll have a context from ambedded documents of ambedkar's speech to help you answer the question. If you don't know the answer, just say that you don't know. Do not try to make up an answer.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5df41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d21fe596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_history(role, content):\n",
    "    messages.append({\"role\": role, \"content\": content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a684749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input():\n",
    "    return input(\"\\nEnter your question about Dr. B.R. Ambedkar's speeches (type 'exit' to quit): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90571f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ollama():\n",
    "    response = ollama.chat(model=MODEL, messages=messages)\n",
    "    answer = response[\"message\"][\"content\"]\n",
    "\n",
    "    update_history(\"assistant\", answer)\n",
    "\n",
    "\n",
    "    print(\"Answer :\", answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For testing purpose \n",
    "\n",
    "\n",
    "# def chat_loop():\n",
    "#     while True:\n",
    "#         user_prompt = get_user_input()\n",
    "\n",
    "#         if user_prompt.lower() in [\"exit\", \"quit\"]:\n",
    "#             print(\"Ending chat. Goodbye!\")\n",
    "#             break\n",
    "\n",
    "#         # Store user's message\n",
    "#         update_history(\"user\", user_prompt)\n",
    "\n",
    "#         # Query model\n",
    "#         ask_ollama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40fe6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b9d70",
   "metadata": {},
   "source": [
    "## Now we will implement Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0096a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vector DB from text file\n",
    "\n",
    "def create_vector_db(text_path=\"speech.txt\", db_dir=\"db\"):\n",
    "    #  Load text\n",
    "    loader = TextLoader(text_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split text into chunks\n",
    "    splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    print(\"Chunks created:\", len(chunks))\n",
    "    print(chunks[0:6])\n",
    "\n",
    "    # Embedding model\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "\n",
    "    # Create vector DB\n",
    "    vectordb = Chroma.from_documents(\n",
    "        chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=db_dir\n",
    "    )\n",
    "\n",
    "    vectordb.persist()\n",
    "    print(f\"Vector DB created & stored at: {db_dir}\")\n",
    "\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc64bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created: 4\n",
      "[Document(metadata={'source': 'speech.txt'}, page_content='Topic: Annihilation of Caste\\nThe real remedy is to destroy the belief in the sanctity of the shastras. \\nHow do you expect to succeed if you allow the shastras to continue to be held as sacred and infallible?'), Document(metadata={'source': 'speech.txt'}, page_content='You must take a stand against the scriptures. Either you must stop the practice of caste or you must stop believing in the shastras. \\nYou cannot have both. \\nThe problem of caste is not a problem of social reform. It is a problem of overthrowing the authority of the shastras.'), Document(metadata={'source': 'speech.txt'}, page_content='So long as people believe in the sanctity of the shastras, they will never be able to get rid of caste. \\nThe work of social reform is like the work of a gardener who is constantly pruning the leaves and branches of a tree without ever attacking the roots.'), Document(metadata={'source': 'speech.txt'}, page_content='The real enemy is the belief in the shastras.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAKSHYA\\AppData\\Local\\Temp\\ipykernel_4900\\2429178534.py:17: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB created & stored at: db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAKSHYA\\AppData\\Local\\Temp\\ipykernel_4900\\2429178534.py:28: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "## Do not run this cell again if you already have db (vector db) as it will create multiple same chunks in the vector DB\n",
    "## But by mistake you do, just delete db folder and run again\n",
    "\n",
    "# vectordb = create_vector_db()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954fa028",
   "metadata": {},
   "source": [
    "### Load vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8550020a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAKSHYA\\AppData\\Local\\Temp\\ipykernel_4900\\4121428995.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n"
     ]
    }
   ],
   "source": [
    "def load_vector_db(db_dir=\"db\"):\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=db_dir,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    return vectordb.as_retriever()\n",
    "\n",
    "retriever = load_vector_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57f2977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_retriever(question, k=2):\n",
    "    retriever = vectordb.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": k}\n",
    "    )\n",
    "\n",
    "    docs = retriever.invoke(question)\n",
    "\n",
    "    # print(\"\\nRetrieved Chunks:\")\n",
    "    # for i, d in enumerate(docs):\n",
    "    #     print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    #     print(d.page_content)\n",
    "\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cbc307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Chunks:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "The real enemy is the belief in the shastras.\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Topic: Annihilation of Caste\n",
      "The real remedy is to destroy the belief in the sanctity of the shastras. \n",
      "How do you expect to succeed if you allow the shastras to continue to be held as sacred and infallible?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content='The real enemy is the belief in the shastras.'),\n",
       " Document(metadata={'source': 'speech.txt'}, page_content='Topic: Annihilation of Caste\\nThe real remedy is to destroy the belief in the sanctity of the shastras. \\nHow do you expect to succeed if you allow the shastras to continue to be held as sacred and infallible?')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing context retriever\n",
    "# context_retriever(\"What does the speech say is the real enemy?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cfd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    # to clear previous history everytime new chat starts\n",
    "    messages.clear()\n",
    "    messages.append({\"role\": \"system\", \"content\": system_prompt})   \n",
    "    while True:\n",
    "        user_question = get_user_input()\n",
    "\n",
    "        if user_question.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"\\nEnding chat. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        print(\"\\nQuestion:\", user_question)\n",
    "\n",
    "        # 1. Retrieve context\n",
    "        docs = context_retriever(user_question)\n",
    "        context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        # 2. Build final prompt for model\n",
    "        final_prompt = f\"\"\"\n",
    "            Use ONLY the context to answer the question.\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question:\n",
    "            {user_question}\n",
    "            \n",
    "            If answer is not in the context, say \"I don't know\".\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "        # 3. Update Contextual user message in history\n",
    "        update_history(\"user\", final_prompt)\n",
    "\n",
    "        # 4. Ask Ollama with context-enhanced prompt\n",
    "        ask_ollama()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34dc5b",
   "metadata": {},
   "source": [
    "1. Direct extraction questions (should answer correctly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b51e950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What does the speech say is the real enemy?\n",
      "\\Answer :   The speech \"Annihilation of Caste\" identifies the belief in the shastras as the real enemy.\n",
      "Question: According to Ambedkar, what is the real remedy for caste problems?\n",
      "\\Answer :   According to Ambedkar, the real remedy for caste problems is to destroy the belief in the sanctity of the shastras.\n",
      "Question: Why does Ambedkar say people cannot get rid of caste?\n",
      "\\Answer :    People cannot get rid of caste because as long as they believe in the sanctity of the shastras. According to Ambedkar, it is a problem of overthrowing the authority of the shastras rather than social reform.\n",
      "Question: What is the relationship between the shastras and caste?\n",
      "\\Answer :    The relationship between the shastras and caste, as per Ambedkar, is that as long as people believe in the sanctity of the shastras, they will never be able to get rid of caste. He considers it a problem of overthrowing the authority of the shastras rather than social reform.\n",
      "Question: Why does Ambedkar criticize social reformers?  What does Ambedkar compare social reform to?  What does the speech say about the sanctity of the shastras?\n",
      "\\Answer :     Ambedkar criticizes social reformers because he believes that the problem of caste is not a problem of social reform but rather a problem of overthrowing the authority of the shastras. He compares social reform to the work of a gardener who is constantly pruning the leaves and branches of a tree without ever attacking the roots. The speech says that as long as people believe in the sanctity of the shastras, they will never be able to get rid of caste.\n",
      "Ending chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0533d52",
   "metadata": {},
   "source": [
    "2. Inference-level questions (answerable only from the context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57ac8314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question: Why does Ambedkar say you must stop believing in the shastras?\n",
      "\n",
      "Answer :    According to the context, Ambedkar says that you must stop believing in the shastras because as long as people believe in their sanctity, they will never be able to get rid of caste. The problem of caste is not a problem of social reform but rather a problem of overthrowing the authority of the shastras. Therefore, he suggests that one must take a stand against the scriptures and either stop the practice of caste or stop believing in the shastras.\n",
      "\n",
      "\n",
      "Question: What problem does Ambedkar consider deeper than social reform?\n",
      "\n",
      "Answer :    The problem that Ambedkar considers deeper than social reform is overthrowing the authority of the shastras.\n",
      "\n",
      "\n",
      "Question: Why can’t someone practice caste and believe in the shastras at the same time?\n",
      "\n",
      "Answer :    According to the given context, it does not explicitly mention why one cannot practice caste and believe in the shastras at the same time. The text emphasizes that either you must stop the practice of caste or stop believing in the shastras as they are interrelated problems and cannot coexist.\n",
      "\n",
      "Ending chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f2130",
   "metadata": {},
   "source": [
    "3. Questions that should return “I don’t know”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5671414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: When was Ambedkar born?\n",
      "Answer :  I don't know. The provided context does not contain information about Dr. B.R. Ambedkar's birth date.\n",
      "\n",
      "Question: Where did Ambedkar deliver this speech?\n",
      "Answer :  I don't know. The provided context does not contain information about where Dr. B.R. Ambedkar delivered his speech on Annihilation of Caste.\n",
      "\n",
      "Question: How long is the entire book ‘Annihilation of Caste’? What reforms did Ambedkar propose in 1940?\n",
      "Answer :  The provided context does not contain information about the length of the book 'Annihilation of Caste' or the specific reforms proposed by Dr. B.R. Ambedkar in 1940. However, it discusses his views on the need to destroy the belief in the sanctity of the shastras as a way to get rid of caste and the idea that social reform is like pruning the leaves and branches of a tree without attacking the roots. To find out more detailed information about Ambedkar's specific proposals for reform, one would need to read his speech or other relevant documents from 1940.\n",
      "\n",
      "Ending chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421fb98",
   "metadata": {},
   "source": [
    "4. Paraphrased or tricky formulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59271e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What must be destroyed to remove the foundation of caste, according to the speech?\n",
      "Answer :  To remove the foundation of caste, according to the speech, one must destroy the belief in the sanctity of the shastras.\n",
      "\n",
      "Question: Why does Ambedkar think social reform is ineffective?\n",
      "Answer :  According to the speech, Ambedkar thinks that social reform is ineffective because it only addresses the symptoms of the problem (pruning leaves and branches) without addressing the root cause, which is the belief in the sanctity of the shastras. He argues that the problem of caste is a problem of overthrowing the authority of the shastras, not just a problem of social reform.\n",
      "\n",
      "Question: What belief prevents society from eliminating caste?\n",
      "Answer :   The belief that prevents society from eliminating caste is the belief in the sanctity of the shastras.\n",
      "\n",
      "Question: What contradiction does Ambedkar point out regarding caste practice and belief in the shastras? and Summarize Ambedkar's argument about why caste cannot be removed without rejecting scriptures.\n",
      "Answer :    Ambedkar points out a contradiction between continuing to practice caste and believing in the shastras as sacred and infallible. He argues that caste cannot be removed without rejecting scriptures because belief in the sanctity of the shastras is the foundation upon which the problem of caste rests. According to Ambedkar, the real remedy for the annihilation of caste is to destroy this belief and overthrow the authority of the shastras.\n",
      "\n",
      "Ending chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7663be32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
